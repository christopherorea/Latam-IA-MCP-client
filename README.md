# Latam-IA MCP Client

[![React](https://img.shields.io/badge/React-2025-blue?logo=react)](https://react.dev/)
[![Vite](https://img.shields.io/badge/Vite-5.0-purple?logo=vite)](https://vitejs.dev/)
[![Gemini](https://img.shields.io/badge/Gemini-API-blueviolet)](https://ai.google.dev/gemini-api)
[![MIT License](https://img.shields.io/badge/License-MIT-green)](LICENSE)
[![Open Source](https://img.shields.io/badge/Open%20Source-Yes-brightgreen)](https://github.com/christopherorea/Latam-IA-MCP-client)
[![Demo en vivo](https://img.shields.io/badge/Demo-GitHub%20Pages-blue)](https://christopherorea.github.io/Latam-IA-MCP-client/)

ğŸš€ **Latam-IA MCP Client** es un conector universal open source para interactuar con sistemas MCP (Model Context Protocol) globales, pensado para AmÃ©rica y el mundo. Su objetivo es facilitar la integraciÃ³n y el acceso a modelos de lenguaje (LLMs) de mÃºltiples proveedores, desde cualquier dispositivo: computadoras, navegadores, telÃ©fonos, relojes inteligentes Â¡y mÃ¡s!

---

## ğŸ“‘ Ãndice

- [Demo en vivo](#-demo-en-vivo)
- [InstalaciÃ³n y ejecuciÃ³n local](#-instalaciÃ³n-y-ejecuciÃ³n-local)
- [Estructura del proyecto](#-estructura-del-proyecto)
- [Requisitos previos](#-requisitos-previos)
- [Seguridad y privacidad](#-seguridad-y-privacidad)
- [Reglas para contribuir](#-reglas-para-contribuir)
- [Â¿CÃ³mo crear un branch?](#-cÃ³mo-crear-un-branch)
- [ValidaciÃ³n](#-validaciÃ³n)
- [TODOs](#todos)
- [Â¿Para quiÃ©n es?](#-para-quiÃ©n-es)
- [Â¿Por quÃ© usarlo?](#-por-quÃ©-usarlo)
- [Patrocinador](#-patrocinador)
- [Licencia](#-licencia)
- [Modos de uso: PWA y extensiÃ³n de Chrome](#modos-de-uso-pwa-y-extensiÃ³n-de-chrome)

---

## ğŸŒ Demo en vivo

[Â¡PruÃ©balo aquÃ­!](https://christopherorea.github.io/Latam-IA-MCP-client/)

---

## âš¡ InstalaciÃ³n y ejecuciÃ³n local

1. **Clona el repositorio:**
   ```bash
   git clone https://github.com/christopherorea/Latam-IA-MCP-client.git
   cd Latam-IA-MCP-client
   ```
2. **Instala las dependencias:**
   ```bash
   npm install
   ```
3. **Configura tu Gemini API Key:**
   - La clave se solicita al iniciar la app y se guarda solo en tu sesiÃ³n local.
   - Puedes obtener una en [Google AI Gemini](https://ai.google.dev/gemini-api/docs/)
4. **Ejecuta en modo desarrollo:**
   ```bash
   npm run dev
   ```
5. **Abre en tu navegador:**
   - Normalmente en [http://localhost:5173](http://localhost:5173)

---

## ğŸ“ Estructura del proyecto

- `components/` â€” Componentes principales de la UI (chat, header, footer, etc.)
- `hooks/` â€” Custom hooks para lÃ³gica de negocio y estado
- `services/` â€” Integraciones con APIs externas (Gemini, OpenAI, Claude, etc.)
- `types.ts` â€” Tipos y contratos TypeScript
- `constants.tsx` â€” Iconos y constantes visuales
- `App.tsx` â€” Componente raÃ­z
- `vite.config.ts` â€” ConfiguraciÃ³n de Vite

---

## ğŸš¦ Requisitos previos

- Node.js >= 18.x
- Navegador moderno
- **Gemini API Key** (por ahora solo disponible este proveedor)

---

## ğŸ”’ Seguridad y privacidad

- Las herramientas y las claves API se almacenan Ãºnicamente en la sesiÃ³n del usuario.
- No se guardan en servidores externos ni se comparten, asegurando que la seguridad depende exclusivamente de quien use el sistema.
- Recomendamos siempre usar claves personales y mantenerlas seguras.

---

## ğŸ› ï¸ Reglas para contribuir

- Usa ramas y nombres de commits siguiendo estas convenciones:
  - `fix/<motivo>` para correcciones de bugs o problemas.
  - `feature/<aÃ±adido>` para nuevas funcionalidades.
  - `refactor/<motivo>` para refactorizaciÃ³n de cÃ³digo.
  - `docs/<motivo>` para cambios en la documentaciÃ³n.
  - `test/<motivo>` para aÃ±adir o mejorar pruebas.
  - `chore/<motivo>` para tareas menores o mantenimiento.
- Toda contribuciÃ³n debe pasar la validaciÃ³n de cÃ³digo y revisiÃ³n por la comunidad.
- Abre un Pull Request explicando claramente el cambio y su impacto.

---

## ğŸ› ï¸ Â¿CÃ³mo crear un branch?

Para contribuir, crea una nueva rama siguiendo estas reglas de nomenclatura:

- Para correcciones de bugs:
  ```bash
  git checkout -b fix/<motivo>
  # Ejemplo:
  git checkout -b fix/arreglo-chat
  ```

- Para nuevas funcionalidades:
  ```bash
  git checkout -b feature/<aÃ±adido>
  # Ejemplo:
  git checkout -b feature/tabs-servidores
  ```

- Para mejoras de documentaciÃ³n:
  ```bash
  git checkout -b docs/<motivo>
  # Ejemplo:
  git checkout -b docs/actualiza-readme
  ```

- Para refactorizaciones:
  ```bash
  git checkout -b refactor/<motivo>
  # Ejemplo:
  git checkout -b refactor/estructura-componentes
  ```

Recuerda siempre crear tu branch desde la rama `main` y hacer un Pull Request cuando termines tu cambio.

---

## âœ… ValidaciÃ³n

- Antes de hacer merge, asegÃºrate de que tu cÃ³digo pase los tests y respete las convenciones del proyecto.
- La comunidad revisarÃ¡ y aprobarÃ¡ los cambios.

---

## TODOs

- [ ] AÃ±adir pruebas unitarias.
- [ ] RefactorizaciÃ³n del cÃ³digo para mayor mantenibilidad.
- [ ] Implementar tabs para intercambiar entre servidores MCP y proveedores LLM.
- [ ] Mejorar la cobertura de tests y documentaciÃ³n.
- [ ] Soporte para mÃ¡s proveedores de LLM (actualmente solo Gemini API Key).

---

## ğŸ‘¥ Â¿Para quiÃ©n es?

- Usuarios, empresas y desarrolladores que quieran interactuar con LLMs y servidores MCP de forma sencilla y segura.
- Miembros de la comunidad LATAM AI y cualquier persona interesada en IA conversacional y protocolos abiertos.
- Cualquiera que desee contribuir, mejorar y mantener una herramienta de IA para todos.

---

## ğŸŒ Â¿Por quÃ© usarlo?

- **ConexiÃ³n universal:** Un solo cliente para todos tus LLMs y servidores MCP.
- **Comunidad:** Crece y evoluciona gracias a las ideas y aportes de usuarios de toda AmÃ©rica y el mundo.
- **Futuro abierto:** Pensado para ser la base de la interacciÃ³n con IA en la regiÃ³n y mÃ¡s allÃ¡.

---

## ğŸ¤ Patrocinador

Este proyecto es patrocinado por [Consultor-IA](https://consultor-ia.tech/).  
Gracias a Consultor-IA por apoyar el desarrollo y la comunidad de LATAM AI.

---

## ğŸ“„ Licencia

Este proyecto es open source bajo licencia MIT.

---

## ğŸ§© Modos de uso: PWA y extensiÃ³n de Chrome

Puedes usar este cliente de tres formas principales:

### 1. Usar como PWA (por defecto)

No necesitas hacer ningÃºn cambio. El proyecto estÃ¡ listo para funcionar como PWA:
- Simplemente ejecuta en desarrollo (`npm run dev`) o despliega el build (`npm run build`).
- El archivo `index.html` ya apunta al manifiesto y service worker de PWA:
  ```html
  <link rel="manifest" id="manifest-link" href="/manifest-pwa.json">
  <script>
    navigator.serviceWorker.register('/service-worker.js')
  </script>
  ```
- Puedes instalar la app como PWA desde el navegador (opciÃ³n "Instalar app" en Chrome, Edge, etc.).

### 2. Crear tu propia extensiÃ³n de Chrome

Si quieres tu propia extensiÃ³n personalizada:
1. Cambia en `index.html` la lÃ­nea del manifiesto por la de extensiÃ³n:
   ```html
   <link rel="manifest" id="manifest-link" href="/manifest.json">
   ```
2. Ejecuta el build del proyecto:
   ```bash
   npm run build
   ```
3. Ve a `chrome://extensions/`, activa "Modo desarrollador" y haz clic en "Cargar descomprimida". Selecciona la carpeta `dist/` generada.

### 3. Probar la extensiÃ³n ya empaquetada

Si solo quieres probar la extensiÃ³n rÃ¡pidamente:
1. Descomprime el archivo `Latam-IA-MCP-client-chrome-v1.zip` que estÃ¡ en la raÃ­z del proyecto.
2. Ve a `chrome://extensions/`, activa "Modo desarrollador" y haz clic en "Cargar descomprimida". Selecciona la carpeta descomprimida.

---

Cada vez que haces merge a `main`, un workflow de GitHub Actions despliega la app en GitHub Pages automÃ¡ticamente.

---

## ğŸ“š CitaciÃ³n

Si este proyecto te resulta Ãºtil, siÃ©ntete libre de citarlo.

```
@misc{latam-ia-mcp-client,
  title={Latam-IA MCP Client: Conector universal open source para LLMs y servidores MCP},
  author={Christopher Orea},
  year={2025},
  howpublished={\url{https://github.com/christopherorea/Latam-IA-MCP-client}},
  note={LinkedIn del autor: https://www.linkedin.com/in/chrisgalleta/}
}
```

Â¡Bienvenido a la revoluciÃ³n de la IA abierta y colaborativa! ğŸŒğŸ¤–

